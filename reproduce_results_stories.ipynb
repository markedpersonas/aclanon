{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alpha-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marked_words import marked_words\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def pprint(dic):\n",
    "    full_list = []\n",
    "    for word in sorted(dic,key=lambda x: x[1],reverse=True):\n",
    "#         print(\"%s, %.2f\" % (word[0],word[1]))\n",
    "        full_list.append(word[0])\n",
    "    return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "talented-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dv3/dv3_story_generations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raising-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marked_words import marked_words\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def pprint(dic):\n",
    "    full_list = []\n",
    "    for word in sorted(dic,key=lambda x: x[1],reverse=True):\n",
    "#         print(\"%s, %.2f\" % (word[0],word[1]))\n",
    "        full_list.append(word[0])\n",
    "    return full_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "canadian-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv3_mw = {}\n",
    "for race in df['race'].unique():\n",
    "    outs = pprint(marked_words(df, [race], ['race'],['a White']))\n",
    "    dv3_mw[race] = outs\n",
    "temps = []\n",
    "for race in df['race'].unique():\n",
    "    temp = pprint(marked_words(df, ['a White'], ['race'],[race]))\n",
    "    temps.extend(temp)\n",
    "seen = Counter(temps).most_common()\n",
    "dv3_mw['a White']=[w for w, c in seen if c == 4]\n",
    "\n",
    "\n",
    "for race in df['gender'].unique():\n",
    "    outs = pprint(marked_words(df, [race], ['gender'],['M']))\n",
    "    dv3_mw[race] = outs\n",
    "temps = []\n",
    "for race in df['gender'].unique():\n",
    "    temp = pprint(marked_words(df, ['M'], ['gender'],[race]))\n",
    "    temps.extend(temp)\n",
    "\n",
    "seen = Counter(temps).most_common()\n",
    "dv3_mw['M']=[w for w, c in seen if c == 2]\n",
    "    \n",
    "    \n",
    "# Top words for intersectional groups\n",
    "for race in df['race'].unique():\n",
    "    for gen in ['N','W']:\n",
    "        dv3_mw[race+gen] = pprint(marked_words(df, [race, gen], ['race', 'gender'],['a White','M']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abroad-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE\n",
      "Mean accuracy across race groups: 0.83 ± 0.06\n",
      "GENDER\n",
      "Mean accuracy across gender groups: 0.87 ± 0.08\n",
      "RACEGENDER\n",
      "Mean accuracy across racegender groups: 0.94 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import sklearn.feature_selection \n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True, decode_error = u'ignore')\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "def anonymize(bio, remove_names=True, remove_gender_markers=True, remove_title=True, replacement=\"\"):\n",
    "    bio = re.sub(r\"\\b(?:[Hh]e|[Ss]he|[Hh]er|[Hh]is|[Hh]im|[Hh]ers|[Hh]imself|[Hh]erself|hes|shes|[Mm][Rr]|[Mm][Rr][sS]|[Mm][Ss]|man|male|bro|bros)\\b\", replacement, bio)\n",
    "    bio = re.sub(r\"african|middleeastern|middleeast|spanishspeaking|mexico|spanish|african-american|black|hispanic|latinx|latine|latina|latino|latin|asian|asian-american|desi|european|europe|asia|middle eastern|arab|white|caucasian|arabic|aapi|bipoc|filipin*|mexic*|india|salvador|cuban|chinese|japanese|korean|china\", replacement, bio)\n",
    "    bio = re.sub(r\"female|genderconforming|cisgender|cis|cisgender|descriptors|AFAB|AMAB|androgynous|butch|effeminate|feminine|femme|manly|masculine|womanly||female|woman|women|lady|ladies|girl|girls|mother|mothers|mom|moms|daughter|daughters|wife|wives|grandmother|grandmothers|grandma|grandmas|sister|sisters|male|bros|guy|guys|boy|boys|father|fathers|dad|dads|son|sons|husband|husbands|grandfather|grandfathers|grandpa|grandpas|brother|brothers\", replacement, bio)\n",
    "    return bio\n",
    "\n",
    "alldata = df.copy()\n",
    "alldata['racegender'] = alldata['race']+alldata['gender']\n",
    "data = alldata['text'].str.lower().replace('[^\\w\\s]','',regex=True)\n",
    "top_words = dict()\n",
    "dv3_svm = {}\n",
    "for st in ['race','gender','racegender']:\n",
    "    print(st.upper())\n",
    "    for d in data:\n",
    "        try:\n",
    "            anonymize(d)\n",
    "        except TypeError:\n",
    "            print(d)\n",
    "    concept_data = [anonymize(d) for d in data]\n",
    "\n",
    "    labels = alldata[st]\n",
    "\n",
    "    bios_data_train, bios_data_test,Y_train,Y_test = train_test_split(concept_data, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    vectorizer = CountVectorizer(analyzer='word',min_df=0.001,binary=False)\n",
    "    X_train = vectorizer.fit_transform(bios_data_train)\n",
    "    X_test = vectorizer.transform(bios_data_test)\n",
    "    accs = []\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for r in alldata[st].unique():\n",
    "        svm = SVC(kernel='linear')\n",
    "        Y_train_bin = Y_train==r\n",
    "        svm.fit(X_train, Y_train_bin)\n",
    "        acc=sklearn.metrics.accuracy_score(Y_test==r,svm.predict(X_test))\n",
    "#         print(\"%s Accuracy: %.2f\"%(r,acc))\n",
    "        accs.append(acc)\n",
    "        coef = svm.coef_.toarray()[0]\n",
    "        _, names = zip(*sorted(zip(coef,feature_names)))\n",
    "#         print(\"Top 10 words: %s\" % str(names[-10:][::-1]))\n",
    "        dv3_svm[r] = names[-10:][::-1]\n",
    "    print(\"Mean accuracy across %s groups: %.2f ± %.2f\"%(st,np.mean(accs),np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bright-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=['a White',\n",
    " 'a Black',\n",
    " 'an Asian',\n",
    " 'a Middle-Eastern',\n",
    " 'a Latine',\n",
    " 'M',\n",
    " 'W','N',\n",
    " 'a WhiteW',\n",
    " 'a BlackW',\n",
    " 'an AsianW',\n",
    " 'a Middle-EasternW',\n",
    " 'a LatineW','a WhiteN', 'a BlackN', 'an AsianN', 'a Middle-EasternN', 'a LatineN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suffering-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps={\n",
    "    \n",
    "    'a White':'White', 'a Black':'Black', 'an Asian':'Asian', 'a Middle-Eastern':'ME', 'a Latine':'Latine', 'M':'\\hline man', 'W':'woman', 'N':'nonbinary', 'a BlackW':'\\\\hline Black W', 'an AsianW':'Asian W', 'a Middle-EasternW':'ME W', 'a LatineW':'Latine W',\n",
    "'a BlackN':'Black NB', 'an AsianN':'Asian NB', 'a Middle-EasternN':'ME NB', 'a LatineN':'Latine NB'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "terminal-carnival",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dv3_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-64cf58310fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         only = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdv3_mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdv3_svm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mtempword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\\\textit{%s}'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dv3_svm' is not defined"
     ]
    }
   ],
   "source": [
    "final_table = {}\n",
    "flags=[]\n",
    "for k in dv3_mw:\n",
    "        boths = []\n",
    "#         only = []\n",
    "        for v in dv3_mw[k]:\n",
    "            if v in dv3_svm[k]:\n",
    "                tempword = '\\\\textit{%s}'%v\n",
    "            else:\n",
    "                tempword = v\n",
    "            boths.append(tempword)\n",
    "        final_table[k]=', '.join(boths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "extras={}\n",
    "for k in dv3_mw:\n",
    "    print(k)\n",
    "    svm_list= dv3_svm[k]\n",
    "    extra_words=[]\n",
    "    for word in svm_list:\n",
    "        if word not in final_table[k]:\n",
    "            extra_words.append(word)\n",
    "    if len(extra_words)>0:\n",
    "        extras[k] = '\\\\textcolor{gray}{(%s)}'%', '.join(extra_words)\n",
    "    else:\n",
    "        extras[k]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "supreme-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White &white, john, megan, \\textcolor{gray}{(sam, out, jack, group, town, mac, understood, over, lila, emi)}\\\\\n",
      "Black &black, tyler, \\textit{nathaniel}, ryder, \\textcolor{gray}{(others, jane, nina, jeremiah, kiara, where, went, only, into)}\\\\\n",
      "Asian &asian, i, \\textit{ling}, \\textit{mei}, \\textit{li}, \\textit{kai}, china, my, \\textit{takashi}, beijing, martial, arts, \\textit{hua}, shii, wei, shanghai, \\textit{tomo}, \\textcolor{gray}{(yujin, chen, city)}\\\\\n",
      "ME &\\textit{middle}, middleeastern, \\textit{ali}, \\textit{east}, \\textit{hassan}, eastern, \\textit{ahmed}, \\textit{village}, \\textit{farrah}, \\textit{farid}, culture, saeed, fatima, desert, \\textcolor{gray}{(began, country)}\\\\\n",
      "Latine &latino, \\textit{maria}, latina, \\textit{juan}, mexico, hard, \\textit{marisol}, \\textit{veronica}, carlos, states, \\textit{rafael}, worked, latin, mexican, \\textit{determined}, her, jose, antonio, united, business, \\textcolor{gray}{(identity, sole, josé, javier)}\\\\\n",
      "\\hline man &he, his, him, man, himself, \\textit{john}, ali, \\textit{juan}, \\textit{takashi}, hed, james, jack, \\textit{carlos}, farid, \\textit{rafael}, martial, marco, jose, \\textcolor{gray}{(ricardo, martin, work, american, been)}\\\\\n",
      "woman &she, her, woman, herself, women, \\textit{mei}, latina, \\textit{maria}, \\textit{li}, career, \\textit{nina}, marisol, independent, \\textit{shed}, \\textit{dreams}, \\textit{fatima}, elizabeth, \\textcolor{gray}{(determined, how, firm)}\\\\\n",
      "nonbinary &\\textit{they}, \\textit{their}, \\textit{nonbinary}, \\textit{identity}, \\textit{gender}, them, were, themselves, \\textit{felt}, person, \\textit{fit}, her, she, like, express, i, quite, acceptance, accepted, who, true, or, didnt, embraced, traditional, binary, accepting, supportive, understand, either, roles, my, self, community, pronouns, judgement, neither, understood, female, male, friends, understanding, labels, people, identified, be, it, queer, accept, expectations, belonging, safe, expression, shii, nathaniel, ryder, tomo, truth, \\textcolor{gray}{(alice, family)}\\\\\n",
      "\\hline Black W &her, she, black, \\textit{sheila}, \\textcolor{gray}{(only, calista, on, career, patrice, lashauna, slowly, stella, kara)}\\\\\n",
      "Asian W &her, she, \\textit{mei}, \\textit{li}, \\textit{ling}, asian, \\textcolor{gray}{(cultural, boss, jinyan, liang, business, ahn, often)}\\\\\n",
      "ME W &her, \\textit{fatima}, \\textcolor{gray}{(village, amina, saba, society, determined, would, aneesa, noora, saraya)}\\\\\n",
      "Latine W &her, she, \\textit{maria}, latina, \\textit{marisol}, linda, \\textcolor{gray}{(lupita, determined, lizette, mariye, consuela, miami, library, after)}\\\\\n",
      "Black NB &they, their, \\textit{nathaniel}, ryder, mica, \\textcolor{gray}{(jane, athena, kiara, darwin, found, lidia, loved, go, other)}\\\\\n",
      "Asian NB &they, their, i, asian, my, \\textit{kai}, \\textit{shii}, tomo, yui, \\textit{ade}, kim, \\textcolor{gray}{(being, niko, for, jai, kiku, community, different)}\\\\\n",
      "ME NB &their, they, aziz, \\textit{mabrouk}, habib, \\textcolor{gray}{(began, hassan, ayah, gender, rafaela, farrah, mazen, nour, strict)}\\\\\n",
      "Latine NB &their, they, \\textit{identity}, \\textit{antonio}, veronica, latinx, \\textit{mauricio}, \\textcolor{gray}{(nonbinary, lino, isabel, sabrina, natalia, sole, could)}\\\\\n"
     ]
    }
   ],
   "source": [
    "# maps = \n",
    "for k in rows:\n",
    "    v = final_table[k]\n",
    "# #     if k\n",
    "#     if k in extras:\n",
    "    try:\n",
    "        print(maps[k]+' &'+v+', '+extras[k]+'\\\\\\\\')\n",
    "    except KeyError:\n",
    "        continue\n",
    "# #     else:\n",
    "#         try:\n",
    "#     #             print(maps[k])\n",
    "#             print(maps[k]+' &'+v+'\\\\\\\\')\n",
    "#         except KeyError:\n",
    "#             continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
